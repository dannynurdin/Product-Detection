{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_LSTM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "avIURF8Orof_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# install dependency\n",
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS4O9ffnu0nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload kaggle.json\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QxOdfAZvC9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# buat folder\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXyih9AbvFtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download data dari api kaggle\n",
        "!kaggle datasets download -d kazanova/sentiment140"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjRpSM1-vn72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract data\n",
        "from zipfile import ZipFile\n",
        "file_name = \"sentiment140.zip\"\n",
        "with ZipFile(file_name, 'r') as zip :\n",
        "  zip.extractall()\n",
        "  print('Extracted')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7WvVJ5Zw8nL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing things\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import joblib\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import gensim\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.layers import Embedding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,LSTM,Dropout\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y3f9-eexGVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baca data\n",
        "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\",encoding='latin-1',header=None)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFAnjPO5xmPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# memberikan nama kolom pada data\n",
        "columns=['target','ids','date','flag','user','text']\n",
        "df.columns=columns\n",
        "df = df.drop(['ids', 'date', 'flag', 'user'], axis=1)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G1rdf92b5TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ambil random 10%\n",
        "#df.sample(frac=0.01)\n",
        "df.sample(n=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-LQVvzJWtnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.target.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PrIkGLCzxlV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download stopwords\n",
        "nltk.download('stopwords')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdX6ydQTzUJR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mengubah nilai column target menjadi kategori\n",
        "df.target.replace({0:'Negative',2:'Neutral',4:'Positive'},inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdNvMkRg3bdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pembersihan data\n",
        "stop_words=set(stopwords.words('english'))\n",
        "stop_words.remove('not')\n",
        "corpus=[]\n",
        "for i in range(0,len(df)):\n",
        "    review=re.sub('@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+',' ',df['text'][i])\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    review=[word for word in review if not word in stop_words]\n",
        "    review=' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVCWiUQW4l1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge hasil pembersihan ke dataset\n",
        "df.text=corpus\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV6sonSS-TEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pembagian data training dan test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df,test_df=train_test_split(df,test_size=0.20,random_state=123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZwZeOEe_pAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cek isi data train\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgbfJWEp_tst",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cek isi data test\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr-j1v8fDkYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implement word to vec\n",
        "documents = [text.split() for text in train_df.text]\n",
        "w2v_model = gensim.models.word2vec.Word2Vec(size=300, window=7, min_count=10, workers=8)\n",
        "w2v_model.build_vocab(documents)\n",
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RKiDDkjEC2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training data\n",
        "w2v_model.train(documents, total_examples=len(documents), epochs=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo_ZNH8tHVWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pengelompokan good\n",
        "w2v_model.wv.most_similar(\"good\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQoopEmZHgXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pengelompoan hate\n",
        "w2v_model.wv.most_similar(\"hate\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqBy7uJqHoEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pengelompokan great\n",
        "w2v_model.wv.most_similar(\"great\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npcYByp7HrS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tokenizizing  \n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_df.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFv5QSzQH5Am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hasil token\n",
        "tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX-bObxrIDGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# jumlah vocab setelah di token\n",
        "vocab_size=len(tokenizer.word_index)+1\n",
        "vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5JBj3HOJD1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training testing\n",
        "X_train = pad_sequences(tokenizer.texts_to_sequences(train_df.text), maxlen=300)\n",
        "X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40JmUBMUJzLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = pad_sequences(tokenizer.texts_to_sequences(test_df.text), maxlen=300)\n",
        "X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p28DvgVNJPKZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train=train_df.target\n",
        "y_train.head()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U3N3e2vJ0h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test=test_df.target\n",
        "y_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWciRhIIJ9Jb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mapping kategori ke 0 dan 1 \n",
        "labelencoder = LabelEncoder()\n",
        "y_train = labelencoder.fit_transform(y_train)\n",
        "y_test=labelencoder.fit_transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4YDHrKWKGLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npmjOdYjKOny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embedding data ke matrik\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  if word in w2v_model.wv:\n",
        "    embedding_matrix[i] = w2v_model.wv[word]\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTQgtGSwKUGA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# penambahan embedding layer\n",
        "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=300, trainable=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtBbcj5JKdNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# modeling lstm sequencial\n",
        "model = Sequential()\n",
        "model.add(embedding_layer)\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "# compile \n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJb9BWoRKiRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# buat callback untuk stop training \n",
        "import tensorflow as tf\n",
        "ACCURACY_THRESHOLD = 0.90\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback): \n",
        "    def on_epoch_end(self, epoch, logs={}): \n",
        "        if(logs.get('accuracy') > ACCURACY_THRESHOLD):   \n",
        "          print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n",
        "          self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "\n",
        "# fit ke model simpan ke history\n",
        "model_history=model.fit(X_train, y_train,batch_size=1024,epochs=15,validation_split=0.2,verbose=1, callbacks=[callbacks])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg4OioW8zYTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# menggabar grafik\n",
        "acc = model_history.history['accuracy']\n",
        "val_acc = model_history.history['val_accuracy']\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "epochs=range(len(acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdObGObEzcEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs,acc,label='Trainin_acc',color='blue')\n",
        "plt.plot(epochs,val_acc,label='Validation_acc',color='red')\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation Accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPLHy6h1zc4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(epochs,loss,label='Training_loss',color='blue')\n",
        "plt.plot(epochs,val_loss,label='Validation_loss',color='red')\n",
        "plt.legend()\n",
        "plt.title(\"Training and Validation loss\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "louKDbyszm__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preposer\n",
        "def preprocess(text):\n",
        "    review=re.sub('@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+',' ',text)\n",
        "    review=review.lower()\n",
        "    review=review.split()\n",
        "    review=[word for word in review if not word in stop_words]\n",
        "    print(review)\n",
        "    review=pad_sequences(tokenizer.texts_to_sequences([review]), maxlen=300)\n",
        "    return review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmOYtLAIzpM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prediksi\n",
        "def prediction(review):\n",
        "    review=preprocess(review)\n",
        "    score=model.predict(review)\n",
        "    score=score[0]\n",
        "    if score<0.4:\n",
        "        print(\"Negative\")\n",
        "    elif score>0.4 and score<0.6:\n",
        "        print(\"Neutral\")\n",
        "    else:\n",
        "        print(\"Positive\")\n",
        "    print(score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-RymWf8zrlq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction(\"the food is not bad\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYsfh2ydVLiO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction(\"the actors are stunning\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuR7_raTVObq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction(\"the movie we watched yesterday screamly unexpected\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ZeM1t3VFgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction(\"too much money\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxtZL0Z3VBQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction(\"movie screamly crazy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOsJaAeA0AjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluasi\n",
        "scores = model.predict(X_test, verbose=1, batch_size=1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RknGWHs00BQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=np.where(scores>0.5,1,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKcC2J-s0F2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred,y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdPmVja30Iyg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# buat report\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}